{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "# run \"pip install -U shorttext\" to install shorttext\n",
    "# to use shorttext, package \"en\" need to be downloaded using command \"python -m spacy download en\"\n",
    "from shorttext.utils import DocumentTermMatrix, standard_text_preprocessor_1\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# function to run entropy with base 2\n",
    "def entropy_2(p):\n",
    "    return entropy(p, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# working directory\n",
    "pwd: str = os.environ['HOME'] + '/work/assignment/assignment-7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus_root: str = pwd + '/MovieReviews'\n",
    "bern_file_count: int = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 180 Berardinelli files: 80 Schwartz files: 100\n"
     ]
    }
   ],
   "source": [
    "files: PlaintextCorpusReader = PlaintextCorpusReader(corpus_root, '.*', encoding='latin-1')\n",
    "\n",
    "bern_files: list = files.fileids()[:bern_file_count]\n",
    "sch_files: list = files.fileids()[bern_file_count:]\n",
    "\n",
    "bern_file_count = len(bern_files)\n",
    "sch_file_count: int = len(sch_files)\n",
    "total_file_count: int = bern_file_count + sch_file_count\n",
    "\n",
    "print('Total files:', len(files.fileids()), 'Berardinelli files:', bern_file_count, \n",
    "      'Schwartz files:', sch_file_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "file_contents: list = [files.raw(file) for file in files.fileids()]\n",
    "print(len(file_contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standard_text_preprocessor_1 provides a standard way of text pre-processing:\n",
    "- removing special characters,\n",
    "- removing numerals,\n",
    "- converting all alphabets to lower cases,\n",
    "- removing stop words, and\n",
    "- stemming the words (using Porter stemmer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = standard_text_preprocessor_1()\n",
    "corpus: list = [preprocessor(sentence).split(' ') for sentence in file_contents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the corpus to a document term matrix \n",
    "- each row represents a document\n",
    "- each column represents the number of occurrences for a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dtm: DocumentTermMatrix = DocumentTermMatrix(corpus, docids=files.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check number of occurrence of the word 'director' in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "director_counts: list = list(dtm.get_token_occurences('director').values())\n",
    "director_docs: list = list(dtm.get_token_occurences('director').keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the entropy for the word 'director'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of `director` in the documents: 7.146642117134548\n"
     ]
    }
   ],
   "source": [
    "print('Entropy of `director` in the documents:', entropy_2(director_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the entropy for the word 'director'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Berardinelli docs having `director`: 77\n",
      "# of Schwartz docs having `director`: 87\n"
     ]
    }
   ],
   "source": [
    "bern_doc_count: int = sum([1 for doc in director_docs if doc in bern_files])\n",
    "bern_no_doc_count: int = bern_file_count - bern_doc_count\n",
    "print('# of Berardinelli docs having `director`:', bern_doc_count)\n",
    "\n",
    "sch_doc_count: int = sum([1 for doc in director_docs if doc in sch_files])\n",
    "sch_no_doc_count: int = sch_file_count - sch_doc_count\n",
    "print('# of Schwartz docs having `director`:', sch_doc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a 2x2 matrix with the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of counts: [[77  3]\n",
      " [87 13]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.reshape((bern_doc_count, bern_no_doc_count, sch_doc_count, sch_no_doc_count), (2,2))\n",
    "print('Matrix of counts:', matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the entropy of the document class (marginal entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal entropy: 0.9910760598382222\n"
     ]
    }
   ],
   "source": [
    "marginal_entropy = entropy_2(np.sum(matrix, axis=1))\n",
    "print('Marginal entropy:', marginal_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the column probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column probabilities: [0.91111111 0.08888889]\n"
     ]
    }
   ],
   "source": [
    "column_prob = np.sum(matrix, axis=0)/total_file_count\n",
    "print('Column probabilities:', column_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the conditional entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column entropy: [0.99731635 0.69621226]\n",
      "Conditional entropy: 0.9705515397056739\n"
     ]
    }
   ],
   "source": [
    "column_entropy = np.apply_along_axis(entropy_2, 0, matrix)\n",
    "print('Column entropy:', column_entropy)\n",
    "\n",
    "conditional_entropy = sum(column_prob * column_entropy)\n",
    "print('Conditional entropy:', conditional_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mutual information between the word 'Director' and the document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information: 0.02052452013254835\n"
     ]
    }
   ],
   "source": [
    "mi = marginal_entropy - conditional_entropy\n",
    "print('Mutual information:', mi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
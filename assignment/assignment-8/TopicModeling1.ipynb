{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import *\n",
    "\n",
    "#import relevant packages for conduct topic modeling analysis\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# working directory\n",
    "pwd: str = os.environ['HOME'] + '/work/assignment/assignment-8'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = pd.read_csv(pwd + '/abcnews-date-text.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#take a look at the content of the 'headline_text' column\n",
    "data_text = data[['headline_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            headline_text\n0       aba decides against community broadcasting lic...\n1          act fire witnesses must be aware of defamation\n2          a g calls for infrastructure protection summit\n3                air nz staff in aust strike for pay rise\n4           air nz strike to affect australian travellers\n...                                                   ...\n271877              tractor towing may have sparked blaze\n271878        truck crash hampers pacific highway traffic\n271879          turning pitch gives australia hope clarke\n271880                       two die in weekend accidents\n271881                       un wary of hezbollah weapons\n\n[271882 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aba decides against community broadcasting lic...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>act fire witnesses must be aware of defamation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a g calls for infrastructure protection summit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>air nz staff in aust strike for pay rise</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>air nz strike to affect australian travellers</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271877</th>\n      <td>tractor towing may have sparked blaze</td>\n    </tr>\n    <tr>\n      <th>271878</th>\n      <td>truck crash hampers pacific highway traffic</td>\n    </tr>\n    <tr>\n      <th>271879</th>\n      <td>turning pitch gives australia hope clarke</td>\n    </tr>\n    <tr>\n      <th>271880</th>\n      <td>two die in weekend accidents</td>\n    </tr>\n    <tr>\n      <th>271881</th>\n      <td>un wary of hezbollah weapons</td>\n    </tr>\n  </tbody>\n</table>\n<p>271882 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#add a column to data_text for the row index\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(271882, 2)\n                                       headline_text  index\n0  aba decides against community broadcasting lic...      0\n1     act fire witnesses must be aware of defamation      1\n2     a g calls for infrastructure protection summit      2\n3           air nz staff in aust strike for pay rise      3\n4      air nz strike to affect australian travellers      4\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(documents.shape)\n",
    "print(documents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#take a look at the content of a document with Index# 4310\n",
    "doc_sample = documents[documents['index'] == 4310].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'rain helps dampen bushfires'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "doc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    headline_text  index\n4310  rain helps dampen bushfires   4310",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4310</th>\n      <td>rain helps dampen bushfires</td>\n      <td>4310</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "documents[documents['index'] == 4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#We will perform the following steps:\n",
    " #Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    " #Words that have fewer than 3 characters are removed.\n",
    " #All stopwords are removed.\n",
    " #Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    " #Words are stemmed — words are reduced to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#a function to perform lemmatize and stem pre-processing steps on the data set. You may \"Google\" each Python method to get the meaning of the parameters.\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#remove na values from the column 'headline_text'\n",
    "documents = documents.dropna(subset=['headline_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['rain', 'helps', 'dampen', 'bushfires']\n\n\n tokenized and lemmatized document: \n",
      "['rain', 'help', 'dampen', 'bushfir']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#select a document to preview after pre-processing\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0               [decid, commun, broadcast, licenc]\n1                               [wit, awar, defam]\n2           [call, infrastructur, protect, summit]\n3                      [staff, aust, strike, rise]\n4             [strike, affect, australian, travel]\n5               [ambiti, olsson, win, tripl, jump]\n6           [antic, delight, record, break, barca]\n7    [aussi, qualifi, stosur, wast, memphi, match]\n8            [aust, address, secur, council, iraq]\n9                         [australia, lock, timet]\nName: headline_text, dtype: object"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "#preprocess'headline_text', save the results as 'processed_docs'\n",
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#create a dictionary from ‘processed_docs’ containing the number of times a word appears in the document set\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<gensim.corpora.dictionary.Dictionary at 0x7f3966f83810>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Filter out tokens that appear in\n",
    " #less than 15 documents (absolute number) or\n",
    " #more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    " #after the above two steps, keep only the first 100000 most frequent tokens.\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(71, 1), (107, 1), (460, 1), (3490, 1)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ],
   "source": [
    "#For each document we create a dictionary reporting how many\n",
    "#words and how many times those words appear. Save this to ‘bow_corpus’, then check our selected document earlier.\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Word 71 (\"bushfir\") appears 1 time.\nWord 107 (\"help\") appears 1 time.\nWord 460 (\"rain\") appears 1 time.\nWord 3490 (\"dampen\") appears 1 time.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], dictionary[bow_doc_4310[i][0]], bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#run LDA using bag of words\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Topic: 0 \nWords: 0.020*\"council\" + 0.020*\"hospit\" + 0.018*\"concern\" + 0.017*\"opposit\" + 0.016*\"plan\" + 0.015*\"work\" + 0.013*\"govt\" + 0.012*\"union\" + 0.012*\"sale\" + 0.012*\"worker\"\nTopic: 1 \nWords: 0.069*\"polic\" + 0.030*\"crash\" + 0.028*\"death\" + 0.023*\"investig\" + 0.023*\"jail\" + 0.016*\"probe\" + 0.014*\"die\" + 0.014*\"driver\" + 0.013*\"victim\" + 0.012*\"inquiri\"\nTopic: 2 \nWords: 0.040*\"warn\" + 0.025*\"miss\" + 0.016*\"fear\" + 0.016*\"search\" + 0.014*\"israel\" + 0.013*\"hop\" + 0.011*\"high\" + 0.011*\"issu\" + 0.011*\"cancer\" + 0.010*\"hit\"\nTopic: 3 \nWords: 0.026*\"water\" + 0.015*\"doctor\" + 0.015*\"strike\" + 0.014*\"expect\" + 0.014*\"liber\" + 0.014*\"close\" + 0.012*\"lebanon\" + 0.012*\"nation\" + 0.012*\"west\" + 0.011*\"rain\"\nTopic: 4 \nWords: 0.042*\"kill\" + 0.023*\"reject\" + 0.023*\"push\" + 0.017*\"farmer\" + 0.017*\"drought\" + 0.014*\"look\" + 0.013*\"blaze\" + 0.011*\"dead\" + 0.011*\"fuel\" + 0.011*\"injur\"\nTopic: 5 \nWords: 0.037*\"govt\" + 0.035*\"urg\" + 0.030*\"plan\" + 0.023*\"fund\" + 0.018*\"council\" + 0.016*\"group\" + 0.015*\"rise\" + 0.014*\"health\" + 0.013*\"boost\" + 0.012*\"seek\"\nTopic: 6 \nWords: 0.018*\"talk\" + 0.018*\"defend\" + 0.016*\"hold\" + 0.016*\"iraq\" + 0.015*\"break\" + 0.014*\"howard\" + 0.012*\"east\" + 0.011*\"troop\" + 0.010*\"bush\" + 0.009*\"blue\"\nTopic: 7 \nWords: 0.040*\"charg\" + 0.035*\"face\" + 0.034*\"court\" + 0.023*\"accus\" + 0.021*\"drug\" + 0.014*\"trial\" + 0.014*\"murder\" + 0.013*\"attack\" + 0.013*\"terror\" + 0.013*\"arrest\"\nTopic: 8 \nWords: 0.022*\"test\" + 0.018*\"protest\" + 0.018*\"open\" + 0.018*\"world\" + 0.014*\"australia\" + 0.014*\"final\" + 0.014*\"aussi\" + 0.014*\"lead\" + 0.012*\"win\" + 0.011*\"victori\"\nTopic: 9 \nWords: 0.021*\"closer\" + 0.019*\"elect\" + 0.015*\"market\" + 0.014*\"nuclear\" + 0.013*\"chief\" + 0.012*\"labor\" + 0.012*\"year\" + 0.011*\"china\" + 0.010*\"increas\" + 0.009*\"criticis\"\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#for each topic, we will explore the words occurring in that topic and its relative weight\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(0, 0.020005198),\n (1, 0.28801462),\n (2, 0.020003535),\n (3, 0.55195034),\n (4, 0.020003535),\n (5, 0.02000861),\n (6, 0.020003535),\n (7, 0.02000354),\n (8, 0.020003535),\n (9, 0.020003535)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "lda_model[bow_corpus[4310]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['rain', 'help', 'dampen', 'bushfir']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 29
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\nScore: 0.5517880916595459\t \nTopic: 0.026*\"water\" + 0.015*\"doctor\" + 0.015*\"strike\" + 0.014*\"expect\" + 0.014*\"liber\" + 0.014*\"close\" + 0.012*\"lebanon\" + 0.012*\"nation\" + 0.012*\"west\" + 0.011*\"rain\"\n\nScore: 0.2881767153739929\t \nTopic: 0.069*\"polic\" + 0.030*\"crash\" + 0.028*\"death\" + 0.023*\"investig\" + 0.023*\"jail\" + 0.016*\"probe\" + 0.014*\"die\" + 0.014*\"driver\" + 0.013*\"victim\" + 0.012*\"inquiri\"\n\nScore: 0.02000872604548931\t \nTopic: 0.037*\"govt\" + 0.035*\"urg\" + 0.030*\"plan\" + 0.023*\"fund\" + 0.018*\"council\" + 0.016*\"group\" + 0.015*\"rise\" + 0.014*\"health\" + 0.013*\"boost\" + 0.012*\"seek\"\n\nScore: 0.020005198195576668\t \nTopic: 0.020*\"council\" + 0.020*\"hospit\" + 0.018*\"concern\" + 0.017*\"opposit\" + 0.016*\"plan\" + 0.015*\"work\" + 0.013*\"govt\" + 0.012*\"union\" + 0.012*\"sale\" + 0.012*\"worker\"\n\nScore: 0.020003542304039\t \nTopic: 0.040*\"charg\" + 0.035*\"face\" + 0.034*\"court\" + 0.023*\"accus\" + 0.021*\"drug\" + 0.014*\"trial\" + 0.014*\"murder\" + 0.013*\"attack\" + 0.013*\"terror\" + 0.013*\"arrest\"\n\nScore: 0.020003536716103554\t \nTopic: 0.040*\"warn\" + 0.025*\"miss\" + 0.016*\"fear\" + 0.016*\"search\" + 0.014*\"israel\" + 0.013*\"hop\" + 0.011*\"high\" + 0.011*\"issu\" + 0.011*\"cancer\" + 0.010*\"hit\"\n\nScore: 0.020003536716103554\t \nTopic: 0.042*\"kill\" + 0.023*\"reject\" + 0.023*\"push\" + 0.017*\"farmer\" + 0.017*\"drought\" + 0.014*\"look\" + 0.013*\"blaze\" + 0.011*\"dead\" + 0.011*\"fuel\" + 0.011*\"injur\"\n\nScore: 0.020003536716103554\t \nTopic: 0.018*\"talk\" + 0.018*\"defend\" + 0.016*\"hold\" + 0.016*\"iraq\" + 0.015*\"break\" + 0.014*\"howard\" + 0.012*\"east\" + 0.011*\"troop\" + 0.010*\"bush\" + 0.009*\"blue\"\n\nScore: 0.020003536716103554\t \nTopic: 0.022*\"test\" + 0.018*\"protest\" + 0.018*\"open\" + 0.018*\"world\" + 0.014*\"australia\" + 0.014*\"final\" + 0.014*\"aussi\" + 0.014*\"lead\" + 0.012*\"win\" + 0.011*\"victori\"\n\nScore: 0.020003536716103554\t \nTopic: 0.021*\"closer\" + 0.019*\"elect\" + 0.015*\"market\" + 0.014*\"nuclear\" + 0.013*\"chief\" + 0.012*\"labor\" + 0.012*\"year\" + 0.011*\"china\" + 0.010*\"increas\" + 0.009*\"criticis\"\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#check the topic distribution for the Document# 4310.\n",
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Score: 0.3369967043399811\t Topic: 0.037*\"govt\" + 0.035*\"urg\" + 0.030*\"plan\" + 0.023*\"fund\" + 0.018*\"council\"\nScore: 0.1965998113155365\t Topic: 0.021*\"closer\" + 0.019*\"elect\" + 0.015*\"market\" + 0.014*\"nuclear\" + 0.013*\"chief\"\nScore: 0.18326738476753235\t Topic: 0.069*\"polic\" + 0.030*\"crash\" + 0.028*\"death\" + 0.023*\"investig\" + 0.023*\"jail\"\nScore: 0.18303442001342773\t Topic: 0.040*\"charg\" + 0.035*\"face\" + 0.034*\"court\" + 0.023*\"accus\" + 0.021*\"drug\"\nScore: 0.01668868213891983\t Topic: 0.018*\"talk\" + 0.018*\"defend\" + 0.016*\"hold\" + 0.016*\"iraq\" + 0.015*\"break\"\nScore: 0.016683712601661682\t Topic: 0.022*\"test\" + 0.018*\"protest\" + 0.018*\"open\" + 0.018*\"world\" + 0.014*\"australia\"\nScore: 0.016683179885149002\t Topic: 0.020*\"council\" + 0.020*\"hospit\" + 0.018*\"concern\" + 0.017*\"opposit\" + 0.016*\"plan\"\nScore: 0.016682641580700874\t Topic: 0.040*\"warn\" + 0.025*\"miss\" + 0.016*\"fear\" + 0.016*\"search\" + 0.014*\"israel\"\nScore: 0.01668216660618782\t Topic: 0.042*\"kill\" + 0.023*\"reject\" + 0.023*\"push\" + 0.017*\"farmer\" + 0.017*\"drought\"\nScore: 0.016681300476193428\t Topic: 0.026*\"water\" + 0.015*\"doctor\" + 0.015*\"strike\" + 0.014*\"expect\" + 0.014*\"liber\"\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#check the topic distribution for a new document (not in the corpus)\n",
    "\n",
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}